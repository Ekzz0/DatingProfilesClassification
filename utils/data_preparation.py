from typing import Tuple, List

import pandas as pd
from sklearn.preprocessing import OrdinalEncoder

from .data_processing import numeric_transform, is_empty_string_analysis
from .re_scripts import split_names, split_message, clean_text, check_phrase_existence, apply_sum_by_phrase, \
    get_name_and_old, get_name, get_old


def select_name_and_old(df: pd.DataFrame):
    df['name_old'] = None
    df['name_old'] = df['message'].apply(get_name_and_old)

    df['name'] = None
    df['old'] = None
    df['name'] = df['name_old'].apply(get_name)
    df['old'] = df['name_old'].apply(get_old)
    df.drop(columns='name_old', inplace=True)
    df.dropna(subset=['name', 'old'], inplace=True)
    df.index = range(len(df))

    # –ü–æ–ª—É—á–∏–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞
    df['name'] = df['name'].apply(split_names)

    return df


def select_the_main_features(path: str):
    pd.options.mode.chained_assignment = None  # default='warn'
    df = pd.read_csv(path)
    # df = pd.read_csv("../data/to_test.csv")
    df.drop(columns='Unnamed: 0', inplace=True)

    # –ó–∞–º–µ–Ω–∞ —Å–µ—Ä–¥–µ—á–∫–∞ –∏ –ª–∞–π–∫–∞ –Ω–∞ 1 –∏ 0 —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ
    oEnc = OrdinalEncoder(categories=[['üëé', '‚ù§Ô∏è']])
    df['class'] = oEnc.fit_transform(df['class'].values.reshape(-1, 1))

    # –†–∞–∑–¥–µ–ª–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞ –∏–º—è –∏ –≤–æ–∑—Ä–∞—Å—Ç
    df = select_name_and_old(df)

    # –†–∞–∑–¥–µ–ª–∏–º –∏–º–µ–Ω–∞ –Ω–∞: –∫—Ä—É—Ç—ã–µ/–Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ/–ø–ª–æ—Ö–∏–µ/–Ω–µ —É–∫–∞–∑–∞–Ω–Ω—ã–µ
    best_names = ['–∫—Å—é—à–∞', '–≤–∏–∫–∞', '–¥–∞—à–∞', '–∞–Ω—è', '–∏—Ä–∏–Ω–∞', '–º–∞—à–∞', '–∫—Ä–∏—Å—Ç–∏–Ω–∞', '–∞–ª–∏—Å–∞', '–ª–∏–∑–∞', '–µ–≤–∞', '—Å–∞—à–∞', '—é–ª—è',
                  '–æ–ª—è', '–¥–∏–∞–Ω–∞', '–ª–µ—Ä–∞', '–∂–µ–Ω—è', '–∞–ª—ë–Ω–∞',
                  '–∞–Ω—Ñ–∏—Å–∞', '–ª–∞—Ä–∏—Å–∞', '–∫–∞—Ä–∏–Ω–∞', '–ø–æ–ª–∏–Ω–∞', '—ç–≤–µ–ª–∏–Ω–∞', '—Ç–∞–Ω—è']
    cool_names = ['—Å–æ–Ω—è', '–∞—Ä–∏–Ω–∞', '–≤–ª–∞–¥–∞', '–Ω–∞–¥—è', '–∫–∞—Ç—è', '–≤–µ—Ä–æ–Ω–∏–∫–∞', '–≤–µ—Ä–æ–Ω–∏–∫–∞', '–∞–Ω–∂–µ–ª–∏–∫–∞', '–ª–µ–Ω–∞', '–Ω–∞—Ç–∞—à–∞',
                  '—Å—Ç–∞—Å—è', '—è–Ω–∞',
                  '–º–∞—Ä–∏–Ω–∞', '—É–ª—å—è–Ω–∞', '–≤–∏–æ–ª–µ—Ç—Ç–∞', '–≥—É–∑–µ–ª—å', '—Å–≤–µ—Ç–∞', '–∞–ª—å–±–∏–Ω–∞', '–≤–∞—Ä—è', '–∫–∞–º–∏–ª–ª–∞', '–º–∏–ª–µ–Ω–∞', '–¥–∏–ª—è',
                  '–ª–∏–ª—è', '—ç–ª–µ–æ–Ω–æ—Ä–∞', '–∞–ª–µc—è', '—Ä–∏—Ç–∞', '–≤–∞—Å—è',
                  '–∑–∞—Ä–∏–Ω–∞', '–≤–∞–ª—è', '–≥–∞–ª—è', '–Ω–∏–Ω–∞', '–∞–Ω–≥–µ–ª–∏–Ω–∞']
    bad_names = ['–¥–∞—è–Ω–∞', '–∞–ª–∏–Ω–∞', '–Ω–∞—Å—Ç—è', '—Å–Ω–µ–∂–∞']
    unknown = ['unknown']

    df['name'].mask(df.name.isin(best_names), 'best_name', inplace=True)
    df['name'].mask(df.name.isin(cool_names), 'norm_name', inplace=True)
    df['name'].mask(df.name.isin(bad_names), 'bad_name', inplace=True)
    df['name'].mask(df.name.isin(unknown), 'unknown_name', inplace=True)

    # 3 - best_name
    # 2 - norm_name
    # 1 - bad_name
    # 0 - unknown_name
    oEnc = OrdinalEncoder(categories=[['unknown_name', 'bad_name', 'norm_name', 'best_name']])
    df['name'] = oEnc.fit_transform(df['name'].values.reshape(-1, 1))

    # –î–∞–Ω–Ω—ã–µ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ "—Ñ–ª–∞–≥–æ–≤"
    cols = []
    col_for_search = 'message'

    # –ü—Ä–æ–≤–µ—Ä–∫–∞, —É–∫–∞–∑–∞–Ω–æ –ª–∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
    reg_exp = [r"\d*\s–∫–º\b|\d*\s–º\b"]
    new_col_name = 'distance_to'
    cols.append(new_col_name)
    value = 1
    df = check_phrase_existence(df, reg_exp, new_col_name, col_for_search, value)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞, —É–∫–∞–∑–∞–Ω –ª–∏ —Ä–æ—Å—Ç
    reg_exp = [r"—Ä–æ—Å—Ç\s*\d\d\d"]
    new_col_name = 'height'
    cols.append(new_col_name)
    value = 1
    df = check_phrase_existence(df, reg_exp, new_col_name, col_for_search, value)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞, —É–∫–∞–∑–∞–Ω–æ –ª–∏ '–∏—â—É –ø–∞—Ä–Ω—è –∏—Ç–¥...'
    reg_exp = [r"–∏—â—É\s–æ—Ç–Ω–æ—à–µ–Ω–∏.|–∏—â—É\s–ø–∞—Ä–Ω—è|—Å–µ—Ä—å.–∑–Ω—ã–µ|–º—É–∂—á–∏–Ω|–≤\s–ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–µ"]
    new_col_name = 'romantic_relationships'
    cols.append(new_col_name)
    value = 2
    df = check_phrase_existence(df, reg_exp, new_col_name, col_for_search, value)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞, —É–∫–∞–∑–∞–Ω–æ –ª–∏ 'fwb|ons...'
    reg_exp = [r"fwb|ons|–æ–Ω—Å|—Ñ–≤–±|–∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä"]
    new_col_name = 'fwb_ons'
    cols.append(new_col_name)
    value = 1
    df = check_phrase_existence(df, reg_exp, new_col_name, col_for_search, value)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞, —É–∫–∞–∑–∞–Ω–æ –ª–∏, —á—Ç–æ —á–µ–ª–æ–≤–µ–∫ –Ω–∏—á–µ–≥–æ –Ω–µ –∏—â–µ—Ç
    reg_exp = [r"–∏—â—É\s*–æ–±—â–µ–Ω–∏–µ|–¥—Ä—É–≥–∞|–¥—Ä—É–∑–µ–π|–ü—Ä–æ—Å—Ç–æ–≥–æ\s—á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ"]
    new_col_name = 'not_looking_for'
    cols.append(new_col_name)
    value = -2
    df = check_phrase_existence(df, reg_exp, new_col_name, col_for_search, value)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞, —É–∫–∞–∑–∞–Ω–æ –ª–∏, —á—Ç–æ —á–µ–ª–æ–≤–µ–∫ –Ω–∏—á–µ–≥–æ –Ω–µ –∏—â–µ—Ç
    reg_exp = [r"–∏–Ω—Å—Ç|inst"]
    new_col_name = 'inst'
    cols.append(new_col_name)
    value = 1
    df = check_phrase_existence(df, reg_exp, new_col_name, col_for_search, value)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞, —É–∫–∞–∑–∞–Ω—ã –ª–∏ –æ—Ç–ø—É–≥–∏–≤–∞—é—â–∏–µ —Ñ—Ä–∞–∑—ã
    reg_exp = [r"—Ç–∞–º\s–ø–æ—Å–º–æ—Ç—Ä–∏–º",
               r"—Ü–≤–µ—Ç—ã",
               r"—Ç–∞—Ç—É|–ø–∏–≤–æ|–ø–∏—Ç—å|–±–∞—Ä|–ø—å—é",
               r"size|–Ω–µ\s—Ö—É–¥—ã—à–∫|–≤\s—Ç–µ–ª–µ",
               r"—Ä–µ–±.–Ω|—Ä–∞–∑–≤–µ–¥.–Ω–∫–∞|—Å\s–ø—Ä–∏—Ü–µ–ø–æ–º",
               r"–∫—É—Ä—é|—Å–∏–≥–∞—Ä–µ—Ç|–º–∞—Ç–µ—Ä—é—Å—å",
               r"–µ—Å—Ç—å\s–ø–∞—Ä–µ–Ω—å|–∑–∞–º—É–∂–µ–º|–∂–µ–Ω–∞—Ç–∞|–Ω–µ\s–∏—â—É\s–æ—Ç–Ω–æ—à–µ–Ω–∏\w|–ø–∞—Ä–Ω—è\s–Ω–µ\s–∏—â—É|–Ω–µ\s–∏—â—É\s–ø–∞—Ä–Ω—è|—Å–æ—Å—Ç–æ—é\s–≤\s–æ—Ç–Ω–æ—à"]
    new_col_name = 'cringe_phrase'
    cols.append(new_col_name)
    value = -3
    df = apply_sum_by_phrase(df, reg_exp, new_col_name, col_for_search, value)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞, —É–∫–∞–∑–∞–Ω—ã –ª–∏ —Å–æ–≤–ø–∞–¥–∞—é—â–∏–µ –∏–Ω—Ç–µ—Ä–µ—Å—ã
    reg_exp = [r"—É—á—É—Å—å|–º–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä|–≤—É–∑|–∫–æ–ª–ª–µ–¥–∂|—É—á–µ–±–µ",
               r"—Ä–∞–±–æ—Ç–∞",
               r"–∏–≥—Ä|—Ñ–∏–ª—å–º|—Å–µ—Ä–∏–∞–ª|–∫–∏–Ω–æ|—á–∏—Ç–∞—é|–∫–æ—Ñ–µ|–º—É–∑—ã–∫",
               r"–ø–æ–ª–∏—Ç–µ—Ö",
               r"–ª—ã–∂|–∫–æ–Ω—å–∫|—Å–Ω–æ—É–±–æ—Ä–¥",
               r"–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä|—Ñ–∏–∑–∏–∫|–º–∞—Ç–µ–º–∞—Ç–∏–∫",
               r"—Ä–æ–∫|–∞–Ω–∏–º–µ|—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ|–≥–∏—Ç–∞—Ä|—Å–ø–æ—Ä—Ç",
               r"–≥—É–ª—è—Ç—å|–ø—Ä–æ–≥—É–ª–∫|—Å—Ö–æ–¥–∏—Ç—å|–∂–∏–≤—ã–µ\s–≤—Å—Ç—Ä–µ—á–∏|–≤—Å—Ç—Ä–µ—á–∏",
               r"–≥–æ—Ç–æ–≤–∏—Ç—å|–≤–∫—É—Å–Ω–æ",
               r"–≤–º–µ—Å—Ç–µ"]
    new_col_name = 'similar_interests'
    cols.append(new_col_name)
    value = 3
    df = apply_sum_by_phrase(df, reg_exp, new_col_name, col_for_search, value)

    # –í—ã–¥–µ–ª–∏–º —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è (–Ω–µ –≤–∫–ª—é—á–∞—è –∏–º—è, –≤–æ–∑—Ä–∞—Å—Ç)
    df['text'] = ''
    df['text'] = df['message'].apply(split_message)

    # –û—á–∏—Å—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç –Ω–µ–Ω—É–∂–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
    df['clean_text'] = df['text'].apply(clean_text)
    df['clean_text'] = df['clean_text'].fillna('')
    df.drop(columns='text', inplace=True)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞, –ø—É—Å—Ç–∞—è –ª–∏ –∞–Ω–∫–µ—Ç–∞
    df['is_empty'] = 0
    cols.append('is_empty')
    df['is_empty'] = df['clean_text'].apply(is_empty_string_analysis)

    # –î–ª–∏–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –∞–Ω–∫–µ—Ç–µ
    df['message_len'] = 0
    df['message_len'] = df['clean_text'].apply(len)
    df['sum'] = df[cols].sum(axis=1)
    # –ü–µ—Ä–µ–≤–æ–¥ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç
    for col in cols:
        numeric_transform(df, col)

    return df, cols
